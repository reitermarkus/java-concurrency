% !TEX TS-program = xelatex
%
\documentclass{article}
\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{upgreek}
\usepackage{enumerate}
\usepackage{setspace}% http://ctan.org/pkg/setspace

\begin{document}
	\title{Exercise Sheet 4 - Documentation}
	\date{}
	\author{DÃ¶tlinger Lukas, Kaltschmid Michael, Reiter Markus}

	\maketitle

  \section{Locks Problem}

  \subsection{Deadlock}

  To show an example of a deadlock, we create two objects, \texttt{first} and \texttt{second}. Then we create two threads, the first of which synchronizes on the first object, then sleeps for 100 ms and then synchronizes on the second object. The second thread first synchronizes on the second object, sleeps for 100 ms and then synchronizes on the first object. This leads to a deadlock, because by the time both threads have slept for 100 ms, the first and second object are both locked by the opposite thread.

  \subsection{Livelock}

  To show an example of a livelock, we have a class \texttt{DinnerTable} which has two methods: \texttt{synchronized void someoneStartedEating()} and \texttt{synchronized boolean hasSomeOneStartedEating()}. We create a variable \texttt{DinnerTable table} and two threads which represent two people sitting at the table. The people at the table are polite, so they won't start eating unless someone else is already eating. In each thread, we wait until someone else has started eating using \texttt{while (!table.hasSomeOneStartedEating())}. If there is someone already eating, the thread also calls \texttt{table.someoneStartedEating()} and outputs a message saying the it has also started eating. This leads to a livelock, because in the beginning no one is already eating, so no thread will start eating.

  \subsection{Starvation}

  To show an example of starvation, we create one object which we will synchronize on. Then we create two threads. Both threads are running a loop in which they synchronize on the object and outut a message saying they are doing some work. The only difference between the two threads is that the second thread also sleeps for 500 ms in each iteration, which leads to the first thread starving.

  \section{Dining Philosophers}

  This task is implemented using 3 Java classes: \texttt{Fork.java}, \texttt{Table.java} and \texttt{Philosopher.java}. \texttt{Fork.java} represents a single object of a Fork. \texttt{Philosopher.java} represents a single philosopher and implements the \texttt{Runnable} interface, so each Philosopher can be executed. \texttt{Table.java} is the class that runs everything. It initializes and equal amount of philosophers and forks. The table has two synchronized methods, \texttt{takeFork()} and \texttt{putBackFork()}, which are used by philospher to take and put back two forks. If a philosopher tries to take a fork and fails, the \texttt{wait()} it is called on it, otherwise it takes the forks, thinks for 3 seconds and then is put waiting, to ensure others can grab the forks aswell. Thus there are no starvations. If forks are put back, \texttt{notifyAll()} is called, to wake up all thinking philosophers. Therefor a deadlock is not possible.

  \section{A Concurrent Program}

  The task is to implement 4 different sorting algorithm - \texttt{Insertion Sort}, \texttt{Quick Sort}, \texttt{Merge Sort} and \texttt{Selection Sort} - where each of them run on a different \texttt{Thread}. When measuring the time complexity of all algorithms, we can see two clear winners, which are \texttt{Quick Sort} and \texttt{Merge Sort}. Those are neck on neck and far beyond the competiton especially as the sample size of the array increases. The results in this regard are not suprising eather as those two algorithms lend themselves for parallelization and have both sutable time complexities with $\mathcal{O}(n\cdot \log(n))$ on their Best-Case and Average-Case. \texttt{Insertion Sort} usually still puts up a good fight when the sample size is not too big. The Differences only really start to show as the sample size increases. Fluctuating results are to be expected as this algorithm for its Best-Case has a complexity of $\mathcal{O}(n)$ and for its Worst-Case $\mathcal {O}(n^{2})$. The worst competitor by far is \texttt{Selection Sort}. The result is somewhat suprising, because it is so consistent in its significance. Despite selection sorts terrible time complexity for every case, which is $\mathcal {O}(n^{2})$, it should still not be that far behind the rest of the algorithms.

  \begin{doublespacing}
    \begin{align*}
      \begin{tabular}{|*{3}{c|}}
        \hline
        $size$ & $sort$ & $ms$ \\
        \hline
        100000 & Merge Sort & 122 \\
        \hline
        100000 & Quick Sort & 180 \\
        \hline
        100000 & Insertion Sort & 248 \\
        \hline
        100000 & Selection Sort & 10930 \\
        \hline
      \end{tabular}
    \end{align*}
  \end{doublespacing}

  \begin{doublespacing}
    \begin{align*}
      \begin{tabular}{|*{3}{c|}}
        \hline
        $size$ & $sort$ & $ms$ \\
        \hline
        1000000 & Merge Sort & 1570 \\
        \hline
        1000000 & Quick Sort & 1934 \\
        \hline
        1000000 & Insertion Sort & 6205 \\
        \hline
        1000000 & Selection Sort & fail \\
        \hline
      \end{tabular}
    \end{align*}
  \end{doublespacing}
\end{document}
